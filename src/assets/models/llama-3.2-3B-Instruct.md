---
id: llama-3.2-3b-instruct
label: Llama3.2 3B
models:
  - quantization: Q4_K_M
    size: 2020
    url: https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q4_K_M.gguf
    recommended: true

  - quantization: Q5_K_M
    size: 2320
    url: https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q5_K_M.gguf
    recommended: false

  - quantization: Q6_K
    size: 2640
    url: https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q6_K.gguf
    recommended: false

  - quantization: Q8_0
    size: 3420
    url: https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q8_0.gguf
    recommended: false
---

![meta](/images/models/meta.png)

# Llama 3.2 3B

Llama 3.2 3B is a compact 3 billion parameter model from Meta's Llama family. It's optimized for instruction-following and conversational AI, offering a balanced mix of performance and efficiency.

This model excels at general-purpose tasks including text generation, summarization, and reasoning. Its moderate size makes it ideal for running locally while still providing high-quality outputs comparable to much larger models.
